{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> __《学术训练与职业伦理工作坊》“文本挖掘”专题__\n",
        "\n",
        "\n",
        "\n",
        "- 罗晨\n",
        "    - 武汉大学新闻与传播学院讲师\n",
        "    - 邮箱：chenluo@whu.edu.cn\n",
        "\n",
        "\n",
        "- 2022年10月28日09:50 - 12:15"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 语义网络分析（semantic network analysis, SMA）领域的重要研究者：[George Barnett](https://communication.ucdavis.edu/people/gbarnett)\n",
        "\n",
        "\n",
        "- SMA适合用来[讲故事](https://journals.sagepub.com/doi/10.1177/08944393211012267)、进行[比较研究](https://www.tandfonline.com/doi/full/10.1080/17513050902759488)、进行[过程研究](https://ascelibrary.org/doi/full/10.1061/%28ASCE%29CO.1943-7862.0002041)\n",
        "\n",
        "\n",
        "- SMA不适合作为一项独立的研究方法，除非你的研究问题非常重要/有趣、用于验证性研究、与其他方法进行交叉验证"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 载入包"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os：和操作系统进行交互\n",
        "# re：正则表达式\n",
        "# jieba：中文分词组件\n",
        "import os, re, jieba\n",
        "# pandas：Python环境中（最）常用的数据分析组件\n",
        "import pandas as pd\n",
        "# jieba.posseg：jieba组件里的词性标注函数\n",
        "import jieba.posseg as pseg\n",
        "# opencc：中文繁简体转换组件\n",
        "from opencc import OpenCC"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T01:57:08.542Z",
          "iopub.status.busy": "2022-10-24T01:57:08.531Z",
          "iopub.status.idle": "2022-10-24T01:57:09.770Z",
          "shell.execute_reply": "2022-10-24T01:57:09.777Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 引入停用词\n",
        "\n",
        "- [中文常用停用词表](https://github.com/goto456/stopwords)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(\"./data/stopwords_common/\"):\n",
        "    print(file)\n",
        "    # 使用mac OS时，需要注意隐藏文件\".DS_Store\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baidu_stopwords.txt\n",
            ".DS_Store\n",
            "scu_stopwords.txt\n",
            "cn_stopwords.txt\n",
            "hit_stopwords.txt\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T01:59:51.597Z",
          "iopub.status.busy": "2022-10-24T01:59:51.592Z",
          "iopub.status.idle": "2022-10-24T01:59:51.609Z",
          "shell.execute_reply": "2022-10-24T01:59:51.612Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建空列表，存储停用词\n",
        "stopwords = list()\n",
        "# 遍历存放停用词表文件夹中的文件\n",
        "for file in os.listdir(\"./data/stopwords_common/\"):\n",
        "    # 排除隐藏文件\n",
        "    if \".DS\" not in file:\n",
        "        with open(\"./data/stopwords_common/\" + file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f.readlines():\n",
        "                stopwords.append(line.strip())\n",
        "print(len(stopwords))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3885\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:04:28.624Z",
          "iopub.status.busy": "2022-10-24T02:04:28.618Z",
          "iopub.status.idle": "2022-10-24T02:04:28.634Z",
          "shell.execute_reply": "2022-10-24T02:04:28.639Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用集合功能来对停用词表去重\n",
        "stopwords = list(set(stopwords))\n",
        "print(len(stopwords))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2313\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:05:57.624Z",
          "iopub.status.busy": "2022-10-24T02:05:57.617Z",
          "iopub.status.idle": "2022-10-24T02:05:57.642Z",
          "shell.execute_reply": "2022-10-24T02:05:57.646Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 引入自定义词"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userdict = list()\n",
        "with open(\"./data/userdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f.readlines():\n",
        "        userdict.append(line.strip())\n",
        "\n",
        "userdict = list(set(userdict))\n",
        "print(len(userdict))\n",
        "\n",
        "with open(\"./data/userdict_new.txt\", \"w\", encoding=\"utf-8\") as t:\n",
        "    for w in userdict:\n",
        "        # n表示名词（noun），可以参考jieba文档来构建自定义词典\n",
        "        t.write(str(w).strip() + \" n\" + \"\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:10:15.739Z",
          "iopub.status.busy": "2022-10-24T02:10:15.733Z",
          "iopub.status.idle": "2022-10-24T02:10:15.752Z",
          "shell.execute_reply": "2022-10-24T02:10:15.760Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 对于引入自定义词典前后的分词结果"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 引入前\n",
        "for w in jieba.cut(\"华南海鲜市场在湖北\"):\n",
        "    print(w)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /var/folders/z_/6b8f_9vs5cn5hx3_jlxf0jq80000gn/T/jieba.cache\n",
            "Loading model cost 0.471 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "华南\n",
            "海鲜\n",
            "市场\n",
            "在\n",
            "湖北\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:11:16.342Z",
          "iopub.status.busy": "2022-10-24T02:11:16.337Z",
          "iopub.status.idle": "2022-10-24T02:11:16.807Z",
          "shell.execute_reply": "2022-10-24T02:11:16.822Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 引入后\n",
        "jieba.load_userdict(\"./data/userdict_new.txt\")\n",
        "\n",
        "for w in jieba.cut(\"华南海鲜市场在湖北\"):\n",
        "    print(w)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "华南海鲜市场\n",
            "在\n",
            "湖北\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:11:41.485Z",
          "iopub.status.busy": "2022-10-24T02:11:41.479Z",
          "iopub.status.idle": "2022-10-24T02:11:41.503Z",
          "shell.execute_reply": "2022-10-24T02:11:41.509Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 分词\n",
        "\n",
        "\n",
        "- [词性表](https://gist.github.com/luw2007/6016931)\n",
        "\n",
        "\n",
        "- 实用工具：[在线正则表达式验证](https://regex101.com/)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用正则表达式定义目标抽取域\n",
        "# 匹配中文\n",
        "pattern_CN = re.compile(r\"[\\u4e00-\\u9fa5]\")\n",
        "# 匹配词性：n - 名词、v - 动词、a - 形容词\n",
        "pattern_init = re.compile(r\"^[n|v|a]\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T02:23:41.691Z",
          "iopub.status.busy": "2022-10-24T02:23:41.687Z",
          "iopub.status.idle": "2022-10-24T02:23:41.699Z",
          "shell.execute_reply": "2022-10-24T02:23:41.702Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义分词函数\n",
        "def tokenize(text):\n",
        "    # 用来存储分词结果的空列表\n",
        "    kept_words = list()\n",
        "    # 进行繁简体转换，并使用词性标注分词器\n",
        "    for w, f in pseg.cut(OpenCC(\"t2s\").convert(str(text).strip())):\n",
        "        # 筛选条件：词语不在停用词表中 + 词语长度大于1 + 中文 + 词性符合指定词性（名/动/形）\n",
        "        if (w not in stopwords) and \\\n",
        "        (len(w) > 1) and \\\n",
        "        (pattern_CN.search(w) != None) and \\\n",
        "        (pattern_init.search(f) != None):\n",
        "            kept_words.append(w)\n",
        "    # 最后一步：拼接列表\n",
        "    return \" \".join(kept_words)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T02:29:44.808Z",
          "iopub.status.busy": "2022-10-24T02:29:44.802Z",
          "iopub.status.idle": "2022-10-24T02:29:44.817Z",
          "shell.execute_reply": "2022-10-24T02:29:44.824Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 引入数据\n",
        "\n",
        "\n",
        "- [Pandas文档](https://pandas.pydata.org/docs/reference/index.html#api)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.read_csv(\"./data/common_user.txt\", \n",
        "                     header=None, \n",
        "                     index_col=None, \n",
        "                     sep=\"delimiter\", \n",
        "                     # 不同解析器的优势不一样\n",
        "                     engine=\"python\")\n",
        "corpus.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>截至4月26日18时，全球新冠肺炎疫情形势</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                   0\n0  北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr\n1  #全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...\n2  清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...\n3                              截至4月26日18时，全球新冠肺炎疫情形势\n4  #唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒..."
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:36:54.574Z",
          "iopub.status.busy": "2022-10-24T02:36:54.569Z",
          "iopub.status.idle": "2022-10-24T02:36:54.590Z",
          "shell.execute_reply": "2022-10-24T02:36:54.594Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看数据维数\n",
        "corpus.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "(1000, 1)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:42:28.674Z",
          "iopub.status.busy": "2022-10-24T02:42:28.670Z",
          "iopub.status.idle": "2022-10-24T02:42:28.683Z",
          "shell.execute_reply": "2022-10-24T02:42:28.687Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更换列名\n",
        "corpus.rename(columns={0: \"content\"}, inplace=True)\n",
        "corpus.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>截至4月26日18时，全球新冠肺炎疫情形势</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                             content\n0  北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr\n1  #全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...\n2  清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...\n3                              截至4月26日18时，全球新冠肺炎疫情形势\n4  #唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒..."
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:44:55.961Z",
          "iopub.status.busy": "2022-10-24T02:44:55.954Z",
          "iopub.status.idle": "2022-10-24T02:44:55.975Z",
          "shell.execute_reply": "2022-10-24T02:44:55.979Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 正式分词"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 调用之前定义的分词函数\n",
        "# lambda是匿名函数写法，传递的参数为形参\n",
        "corpus[\"tokens\"] = corpus[\"content\"].apply(lambda x: tokenize(x))\n",
        "corpus.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.76 s, sys: 93 ms, total: 4.85 s\n",
            "Wall time: 4.85 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr</td>\n      <td>北京 公布 新冠肺炎 确诊病例 活动 小区 场所</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...</td>\n      <td>全国性 哀悼 活动 蜡烛 挚爱 留在 深切 哀悼 抗击 新冠肺炎 疫情 斗争 牺牲 烈士 逝...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...</td>\n      <td>清明 时节 心情 探望 长空 思绪 忧怀 英烈 新冠 湿巾 举国 龙人 满怀 同胞 英魂 感...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>截至4月26日18时，全球新冠肺炎疫情形势</td>\n      <td>全球 新冠肺炎 疫情 形势</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒...</td>\n      <td>唐山 确诊 首例 新型肺炎 病例 坐标 河北省 唐山市 迁安市 沙河 驿镇 红庙子 家家户户 消毒</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                             content  \\\n0  北京公布2月18日新发新冠肺炎确诊病例活动过的小区或场所 http://t.cn/A6h0lufr   \n1  #全国性哀悼活动# [蜡烛]有些人的挚爱却永远留在了这个冬天。深切哀悼抗击新冠肺炎疫情斗争牺...   \n2  清明时节心情凝，探望长空思绪浓。忧怀自古英烈魂，更为新冠泪湿巾。天灾人祸举国哀，十亿龙人泪满...   \n3                              截至4月26日18时，全球新冠肺炎疫情形势   \n4  #唐山确诊首例新型肺炎病例#坐标河北省唐山市迁安市沙河驿镇红庙子村，我们村开始给家家户户消毒...   \n\n                                              tokens  \n0                           北京 公布 新冠肺炎 确诊病例 活动 小区 场所  \n1  全国性 哀悼 活动 蜡烛 挚爱 留在 深切 哀悼 抗击 新冠肺炎 疫情 斗争 牺牲 烈士 逝...  \n2  清明 时节 心情 探望 长空 思绪 忧怀 英烈 新冠 湿巾 举国 龙人 满怀 同胞 英魂 感...  \n3                                      全球 新冠肺炎 疫情 形势  \n4  唐山 确诊 首例 新型肺炎 病例 坐标 河北省 唐山市 迁安市 沙河 驿镇 红庙子 家家户户 消毒  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:51:57.154Z",
          "iopub.status.busy": "2022-10-24T02:51:57.147Z",
          "iopub.status.idle": "2022-10-24T02:52:02.024Z",
          "shell.execute_reply": "2022-10-24T02:52:02.040Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 核验空行，避免后续汇报出错\n",
        "corpus[corpus[\"tokens\"].apply(lambda x: len(x.strip().split())) == 0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>『COVID-19: genetic network analysis provides ‘...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>Coronavirus: 42 more cases in UK, taking total...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>Hanoi has had the first COVID-19 infection.  t...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>Xi Focus: Xi calls for all-out global war agai...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>PHEIC</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>Coronavirus: How California kept ahead of the ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>Xi Focus: Xi calls for all-out global war agai...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                               content tokens\n145  『COVID-19: genetic network analysis provides ‘...       \n249  Coronavirus: 42 more cases in UK, taking total...       \n449  Hanoi has had the first COVID-19 infection.  t...       \n546  Xi Focus: Xi calls for all-out global war agai...       \n549                                              PHEIC       \n578  Coronavirus: How California kept ahead of the ...       \n589  Xi Focus: Xi calls for all-out global war agai...       "
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:54:15.131Z",
          "iopub.status.busy": "2022-10-24T02:54:15.127Z",
          "iopub.status.idle": "2022-10-24T02:54:15.140Z",
          "shell.execute_reply": "2022-10-24T02:54:15.147Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看空行数量\n",
        "corpus[corpus[\"tokens\"].apply(lambda x: len(x.strip().split())) == 0].shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "(7, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:55:31.183Z",
          "iopub.status.busy": "2022-10-24T02:55:31.179Z",
          "iopub.status.idle": "2022-10-24T02:55:31.193Z",
          "shell.execute_reply": "2022-10-24T02:55:31.197Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 仅保留非空行\n",
        "corpus = corpus[corpus[\"tokens\"].apply(lambda x: len(x.strip().split())) > 0]\n",
        "corpus.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "(993, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:55:59.765Z",
          "iopub.status.busy": "2022-10-24T02:55:59.759Z",
          "iopub.status.idle": "2022-10-24T02:55:59.784Z",
          "shell.execute_reply": "2022-10-24T02:55:59.790Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 重新设定索引，避免后续出错\n",
        "corpus.reset_index(drop=True, inplace=True)\n",
        "corpus.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>988</th>\n      <td>《独家｜上海研发新冠人源细胞疫苗，科学家已亲试第一针》自新冠肺炎疫情发生以来，我国的科研攻关...</td>\n      <td>独家 上海 新冠 人源 细胞 疫苗 科学家 新冠肺炎 疫情 发生 科研 攻关组 设立 疫苗 ...</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>#山西新增7例新型肺炎#只要B类控制住了，就能放心了。所以各位尽量别隐瞒自己的行动路线，没事...</td>\n      <td>山西 新增 新型肺炎 控制 放心 隐瞒 路线 出门 扎堆 显示 地图</td>\n    </tr>\n    <tr>\n      <th>990</th>\n      <td>『全国新型肺炎疫情实时动态 - 丁香园·丁香医生』http://t.cn/A6vBv3yL</td>\n      <td>全国 新型肺炎 疫情 动态 丁香 丁香 医生</td>\n    </tr>\n    <tr>\n      <th>991</th>\n      <td>#追星史大battle##眼泪及结膜分泌物存在新冠病毒#</td>\n      <td>追星 史大 眼泪 结膜 分泌物 新冠病毒</td>\n    </tr>\n    <tr>\n      <th>992</th>\n      <td>新冠期间比平时上班还忙，各种岗位轮换，还有线上教学各种事，我19年年假还没休呢，说好的三月带...</td>\n      <td>新冠 上班 岗位 轮换 教学 没休 说好 沙子 哪吒 委屈 算了 头箍 旅游 米虫 破坏 大...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                               content  \\\n988  《独家｜上海研发新冠人源细胞疫苗，科学家已亲试第一针》自新冠肺炎疫情发生以来，我国的科研攻关...   \n989  #山西新增7例新型肺炎#只要B类控制住了，就能放心了。所以各位尽量别隐瞒自己的行动路线，没事...   \n990      『全国新型肺炎疫情实时动态 - 丁香园·丁香医生』http://t.cn/A6vBv3yL   \n991                       #追星史大battle##眼泪及结膜分泌物存在新冠病毒#   \n992  新冠期间比平时上班还忙，各种岗位轮换，还有线上教学各种事，我19年年假还没休呢，说好的三月带...   \n\n                                                tokens  \n988  独家 上海 新冠 人源 细胞 疫苗 科学家 新冠肺炎 疫情 发生 科研 攻关组 设立 疫苗 ...  \n989                 山西 新增 新型肺炎 控制 放心 隐瞒 路线 出门 扎堆 显示 地图  \n990                             全国 新型肺炎 疫情 动态 丁香 丁香 医生  \n991                               追星 史大 眼泪 结膜 分泌物 新冠病毒  \n992  新冠 上班 岗位 轮换 教学 没休 说好 沙子 哪吒 委屈 算了 头箍 旅游 米虫 破坏 大...  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T02:58:33.928Z",
          "iopub.status.busy": "2022-10-24T02:58:33.924Z",
          "iopub.status.idle": "2022-10-24T02:58:33.936Z",
          "shell.execute_reply": "2022-10-24T02:58:33.940Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. SMA第一步：统计词频"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 需要去除检索词（避免超大集群出现），以及一些之前处理步骤中忽略的意义含量较低的词\n",
        "dump = [\"新冠\", \"新肺炎\", \"新型肺炎\", \"国际公共卫生紧急事件\", \"新冠肺炎\", \"新型冠状病毒肺炎\", \"肺炎\", \"不明原因肺炎\", \"不明肺炎\", \n",
        "        \"新冠疫情\", \"疫情\", \"新型冠状病毒\", \"肺炎疫情\", \"冠状\", \"冠状病毒\", \"新型冠状\", \"新冠病毒\", \"地图\", \"显示\", \"头条\", \n",
        "        \"文章\", \"微博\", \"视频\", \"真的\"]"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T03:00:19.793Z",
          "iopub.status.busy": "2022-10-24T03:00:19.788Z",
          "iopub.status.idle": "2022-10-24T03:00:19.803Z",
          "shell.execute_reply": "2022-10-24T03:00:19.807Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy：常用的科学计算组件\n",
        "import numpy as np\n",
        "# collections：可以扩展Python内置的数据类型\n",
        "from collections import defaultdict\n",
        "# itertools：实现迭代功能的组件，可以快速计算排列组合\n",
        "from itertools import combinations"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T03:44:36.506Z",
          "iopub.status.busy": "2022-10-24T03:44:36.500Z",
          "iopub.status.idle": "2022-10-24T03:44:36.512Z",
          "shell.execute_reply": "2022-10-24T03:44:36.517Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建defaultdict数据类型来统计词频\n",
        "word_freq = defaultdict(int)\n",
        "\n",
        "for line in corpus[\"tokens\"]:\n",
        "    for w in line.strip().split():\n",
        "        if w not in dump:\n",
        "            word_freq[w] += 1\n",
        "\n",
        "with open(\"./data/word_freq.txt\", \"w\", encoding=\"utf-8\") as t:\n",
        "    # 根据词频对词语进行排列（从高到低）\n",
        "    for w, f in sorted(dict(word_freq).items(), key=lambda x: x[1], reverse=True):\n",
        "        t.write(w + \",\" + str(f) + \"\\n\")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T03:48:58.004Z",
          "iopub.status.busy": "2022-10-24T03:48:57.998Z",
          "iopub.status.idle": "2022-10-24T03:48:58.012Z",
          "shell.execute_reply": "2022-10-24T03:48:58.018Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. SMA第二步：构建语义矩阵"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取前100个高频词\n",
        "word_freq_100 = list()\n",
        "\n",
        "word_freq = pd.read_csv(\"./data/word_freq.txt\", \n",
        "                        header=None, \n",
        "                        index_col=None, \n",
        "                        sep=\",\", \n",
        "                        dtype={0: str, 1: np.float64})\n",
        "word_freq.rename(columns={0: \"词语\", 1: \"词频\"}, \n",
        "                 inplace=True)\n",
        "\n",
        "for w in word_freq[\"词语\"][:100]:\n",
        "    word_freq_100.append(w)\n",
        "\n",
        "print(len(word_freq_100))\n",
        "print(word_freq_100[:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['中国', '确诊', '美国', '武汉', '病例', '全国', '抗击', '新增', '患者', '加油']\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T03:51:15.159Z",
          "iopub.status.busy": "2022-10-24T03:51:15.152Z",
          "iopub.status.idle": "2022-10-24T03:51:15.224Z",
          "shell.execute_reply": "2022-10-24T03:51:15.229Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 存储两个词语之间的关系\n",
        "edges = defaultdict(int)\n",
        "\n",
        "for content in corpus[\"tokens\"]:\n",
        "    overlap = set(content.strip().split()) & set(word_freq_100)\n",
        "    # 检验每一条微博的分词结果与前100个高频词之间是否存在交集\n",
        "    if len(overlap) >= 2:\n",
        "        idx = 0\n",
        "        while idx <= len(content.strip().split()):\n",
        "            # 检验我们设定的5-word窗口中是否存在高频词共现\n",
        "            result = list(set(content.strip().split()[idx: idx + 5]) & overlap)\n",
        "            # 存在共现的话……\n",
        "            if len(result) >= 2:\n",
        "            # 无向网络，不考虑词语的先后顺序\n",
        "                result.sort()\n",
        "                for pair in combinations(result, 2):\n",
        "                    # 规避重复的共现统计\n",
        "                    if content.strip().split()[idx: idx + 5][0] in pair:\n",
        "                        edges[pair] += 1\n",
        "            idx += 1\n",
        "\n",
        "with open(\"./data/matrix.csv\", \"w\", encoding=\"utf-8\") as t:\n",
        "    t.write(\"source, target, weight\" + \"\\n\")\n",
        "    for dyad, weight in sorted(dict(edges).items(), key=lambda x: x[1], reverse=True):\n",
        "        t.write(dyad[0] + \",\" + dyad[1] + \",\" + str(weight) + \"\\n\")"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-10-24T03:56:12.655Z",
          "iopub.status.busy": "2022-10-24T03:56:12.621Z",
          "iopub.status.idle": "2022-10-24T03:56:12.663Z",
          "shell.execute_reply": "2022-10-24T03:56:12.671Z"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. SMA第三部：语义网络可视化"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"./corpus_network.png\" width=\"600\" align=\"middle\">"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "gist_id": "eb41f79c6c435e1b9267c882766829b9",
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
